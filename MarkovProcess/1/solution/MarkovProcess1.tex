%!Mode:: "TeX:UTF-8"
%!TEX encoding = UTF-8 Unicode
%!TEX TS-program = xelatex
\documentclass{ctexart}
\newif\ifpreface
\prefacetrue
\input{../../../global/all}
\begin{document}
\large
\setlength{\baselineskip}{1.2em}
\date{Beijing Normal University}
\ifpreface
  \input{../../../global/preface}
  \newgeometry{left=2cm,right=2cm,top=2cm,bottom=2cm}
\else
  \newgeometry{left=2cm,right=2cm,top=2cm,bottom=2cm}
  \maketitle
\fi
%from_here_to_type
\(%a1%a\)
\begin{problem}\label{pro:1}
  Assume \((\mathscr{F}_t:t \geq 0,t \in \mathbb{R})\) is a filtration.
  For \(t \geq 0\) we let \(\mathscr{F}_{t +}:=\bigcap_{s>t}\mathscr{F}_s\).
  Prove that \(\mathscr{F}_t \subset \mathscr{F}_{t +}\) and \((\mathscr{F}_{t +}:t \geq 0)\) is a filtration.
\end{problem}
\begin{enumerate}
  \item Since \((\mathscr{F}_t: t \geq 0, t \in \mathbb{R})\) is a filtration,
    \(\forall s >  t\), \(\mathscr{F}_s \supset \mathscr{F}_t\), then by the
    definition of \(\mathscr{F}_{t +}\), \(\forall s > t \),
    \( \forall x \in \mathscr{F}_t\), \(x \in \mathscr{F}_s\),
    so \(x \in \mathscr{F}_{t+}\).
    Therefore, \(\mathscr{F}_t \subset \mathscr{F}_{t +}\).
  \item Since \(\forall s> t\), \(\mathscr{F}_s \) is a \(\sigma\)-algebra, so
    it is obvious that \(\mathscr{F}_{t +}\) is a \(\sigma\)-algebra.
    \(\forall r > t\), \(\forall s > r\), \(\mathscr{F}_s \supset \mathscr{F}_r \supset \mathscr{F}_t\),
    then \(\bigcap_{s > r}\mathscr{F}_s \supset \bigcap_{s>t}\mathscr{F}_s\),
    that is \(\mathscr{F}_{r +} \supset \mathscr{F}_{t +}\).
\end{enumerate}
\begin{problem}\label{pro:2}
  Assume \((X_t:t \geq 0,t \in \mathbb{R})\) is a stochastic process on probability space \((\Omega,\mathscr{F},\mathbb{P})\).
  Prove that \(\forall s,t \geq 0,\varepsilon >0,\{\rho(X_s,X_t) \geq \varepsilon\} \in \mathscr{F}\).
\end{problem}
\begin{lemma}\label{lem:2.1}
  \(\{\rho(X_s, X_t) < \varepsilon\} = \bigcup_{q \in D}\{\rho(X_s, q)+\rho(X_t, q) < \varepsilon\}\),
  where \(D:= E \cap Q^d\), \(E = R^d\).

\end{lemma}
\begin{proof}
  \begin{enumerate}
    \item Since \(\rho(X_s,X_t)< \rho(X_s,q)+\rho(X_t,q) < \varepsilon\), then
      \(\{\rho(X_s, X_t) < \varepsilon\} \subset \bigcup_{q \in D}\{\rho(X_s, q)+\rho(X_t, q) < \varepsilon\}\),
    \item Only need to prove that if \(\rho(X_s, X_t) < \varepsilon\),
      then \(\exists q \in D, \rho(X_s,q)+\rho(X_t,q) < \varepsilon\).
      Since \(D\) is dense in \(E\), \(\exists q \in D\) s.t.
      \(\rho(X_s,q) \leq \frac{\varepsilon - \rho(X_s,X_t)}{4}\), so
      \(\rho(X_t,q)+\rho(X_s,q) \leq \rho(X_t,X_s)+2\rho(X_s,q) \leq \rho(X_t,X_s)+ \frac{\varepsilon - \rho(X_s,X_t)}{2} < \varepsilon \).
  \end{enumerate}

\end{proof}
\begin{lemma}\label{lem:2.2}
  \((\Omega,\mathscr{F},\mathbb{P})\) is a probability space, \((E,\mathscr{E})\) is a
  measurable space, \((E,\rho)\) is a distance space.
  \((X_t:t \geq 0, t \in \mathbb{R})\) is a stochastic process from
  \((\Omega,\mathscr{F},\mathbb{P})\) to \((E,\mathscr{E})\).
  If \((E, \rho)\) is separable, then \(\mathscr{B}(E)^2= \mathscr{B}(E^2)\).
  Moreover, if \(\mathscr{E} = \mathscr{B}(E)\), then \(\forall \varepsilon>0, s,t \geq 0, \{\rho(X_s,X_t) \geq \varepsilon\} \in \mathscr{F}\).

\end{lemma}
\begin{proof}
  \begin{enumerate}
    \item Let \(\mathscr{C}\) be all the open set of \((E,\rho)\), \(\mathscr{B}(E)\) be the Borel algebra
      of \((E,\rho)\). Then \(\mathscr{B}(E) = \sigma(\mathscr{C})\), where \(\sigma(\mathscr{C})\)
      means the \(\sigma\) algebra generated from \(\mathscr{C}\).
      Then \(\mathscr{B}(E^2)= \sigma(\{A \times B: A, B \in \mathscr{C}\}) \supset \sigma(\{A \times E :A \in \mathscr{C}\}) = \sigma(\mathscr{C})\times E=\mathscr{B}(E) \times E\).
      By the same way, we can get that \(E \times \mathscr{B}(E) \subset \mathscr{B}(E^2)\).
      \(\forall A,B \in \mathscr{B}(E)\), \(A \times B\), then \( A \times B= (A \times E) \cap (E \times B) \in \mathscr{B}(E) \times E \cap E \times \mathscr{B}(E) \subset \mathscr{B}(E^2)\).
      Therefore, \(\mathscr{B}(E)^2 = \sigma(\{A \times B: A, B \in \mathscr{B}(E)\}) \subset \mathscr{B}(E^2)\).
      Since \((E,\rho)\) is separable, then \(\exists \mathscr{D} \subset \mathscr{C}\), which
      is a countable topology base of \((E,\rho)\).
      Then \(\forall A,B \in \mathscr{C}, A \times B \subset \sigma(\mathscr{D}^2)\),
      and \(\sigma(\mathscr{D}^2) \subset \mathscr{B}(E^2)\),
      so \(\mathscr{B}(E^2)= \sigma(D^2)\).
      Besides, oboviously \(\sigma(\mathscr{D}^2) \subset \mathscr{B}(E)^2\).
      Therefore, \(\mathscr{B}(E^2) \subset \mathscr{B}(E)^2\).
      Then \(\mathscr{B}(E^2) = \mathscr{B}(E)^2\).
    \item Since \(\{(x,y) \in E^2: \rho(x,y) \geq \varepsilon\} \in \mathscr{B}(E^2) = \mathscr{B}(E)^2\),
      then \(\exists A \in \mathscr{B}(E)^2\) s.t.
      \(\{(x,y) \in E^2: \rho(x,y) \geq \varepsilon\} = A\).
      Let \(\mathscr{H}:= \{B \in \mathscr{B}(E)^2: \{(X_s,X_t) \in B\} \in \mathscr{F}\}\).
      Next, we will prove \(\mathscr{H} = \mathscr{B}(E)^2\).
      \begin{enumerate}
        \item \(\mathscr{H}\) is a \(\sigma\)-algebra: obviously, \(E^2 \in \mathscr{H}\).
          If \(B \in \mathscr{H}\), then \(\{(X_s,X_t) \in B \} \in \mathscr{F}\).
          So \(\{(X_s,X_t) \in B^c\} = \{(X_s,X_t) \in B\}^c \in \mathscr{F}\).
          Thus, \(B^c \in \mathscr{F}\).
          If \((B_n \in \mathscr{F}: n \in \mathbb{N}^{+})\), then \(\{(X_s,X_t) \in B_n\} \in \mathscr{F}\),
          then \(\{(X_s,X_t) \in \bigcup_{n \in \mathbb{N}^{+}} B_n\} = \bigcup_{n \in \mathbb{N}^{+}} \{(X_s,X_t) \in B_n\} \in \mathscr{F}\).
        \item \(\mathscr{H} \supset \{A_1 \times A_2: A_1, A_2 \in \mathscr{B}(E)\}\):\\
          Since \(\{(X_s,X_t) \in A_1 \times A_2\} = \{X_s \in A_1\} \cap \{X_t \in A_2\} \in \mathscr{F}\),
          then \(A_1 \times A_2 \in \mathscr{F}\).
      \end{enumerate}

      Then, \(\{\rho(X_s,X_t) \geq \varepsilon\} = \{(X_s,X_t) \in A\} \in \mathscr{F}\).

  \end{enumerate}
\end{proof}

\begin{solution}
  \begin{enumerate}
    \item First way to solve the problem:\\
      Since \(\mathscr{F} \) is a \(\sigma\)-algebra, then it is equal to
      prove that \(\forall s,t \geq 0, \varepsilon > 0, \{\rho(X_s,X_t) < \varepsilon\} \in \mathscr{F}\).
      By \Cref{lem:2.1} and \(D\) is countable, only need to prove that \(\forall q \in D, \{\rho(X_s,q)+ \rho(X_t,q) < \varepsilon\} \in \mathscr{F}\).
      And obviously, \(\{\rho(X_s,q) + \rho(X_t,q) < \varepsilon\} = \bigcup_{p \in D \cap [0, \varepsilon]}\{\rho(X_s,q)< p, \rho(X_t,q)< \varepsilon - p\}\).
      So only need to prove that \(\{\rho(X_s,q) < p , \rho(X_t,q) < \varepsilon - p\} \in \mathscr{F}\).
      Since \(\{\rho(X_s,q) < p , \rho(X_t,q) < \varepsilon - p\}\)
      = \(\{\rho(X_s,q) < p\}\cap \{\rho(X_t,q) < \varepsilon - p\} \),
      and \((X_t: t \geq 0, t \in \mathbb{R})\) is a stochastic process,
      then \(\{\rho(X_s,q) < p\}, \{\rho(X_t,q) < \varepsilon - p\} \in \mathscr{F}\).
    \item Second way to solve the problem:\\
      Since \(E \subset \mathbb{R}^d, \mathscr{E} = E \cap \mathscr{B}^d\), so \((E, \rho)\) can be a separable distance space,
      where \(\rho\) is the distance in \(\mathbb{R}^d\). By \Cref{lem:2.2}, we get \(\{\rho(X_s,X_t) \geq \varepsilon\} \in \mathscr{F} \).
  \end{enumerate}
\end{solution}

\begin{problem}\label{pro:3}
  Let \(\mathscr{D}_X:=\{\mu_J^X:J \in S(I)\}\) be the family of finite-dimentional distributions of a stochastic process \((X_t:t \geq 0,t \in \mathbb{R})\).
  \(\forall (s_1,s_2)\in S(I)\) and \(J=(t_1,\cdots,t_n)\in S(I)\), write \(K_1:=(s_1,s_2,t_1,\cdots,t_n) \in S(I),K_2:=(s_2,s_1,t_1,\cdots,t_n) \in S(I)\).
  Take \(A_1,A_2 \in \mathscr{E},B \in \mathscr{E}^n\), prove that
  \[
    \mu^X_{K_1}(A_1 \times A_2 \times B)=\mu^X_{K_2}(A_2 \times A_1 \times B)
  \]
  and
  \[
    \mu^X_{K_1}(E \times E \times B)=\mu^X_{K_2}(E \times E \times B)=\mu^X_{J}(B)
  \]
\end{problem}
\begin{solution}
  By the definition of \(\mu^X_{J}(H):=\mathbb{P}\{(X_{t_1},\cdots,X_{t_n}) \in H\}\),
  where \(J = (t_1,\cdots,t_n) \in S(I)\), \(H \in \mathscr{F}\).
  Then
  \begin{equation}
    \begin{aligned}
        & \mu^X_{K_1}(A_1 \times A_2 \times B)                                                 \\
      = & \mathbb{P}(\{(X_{s_1},X_{s_2},X_{t_1},\cdots,X_{t_n}) \in A_1 \times A_2 \times B\}) \\
      = & \mathbb{P}(\{X_{s_1} \in A_1, X_{s_2} \in A_2, (X_{t_1},\cdots,X_{t_n}) \in B \})    \\
      = & \mathbb{P}(\{(X_{s_2},X_{s_1},X_{t_1},\cdots,X_{t_n}) \in A_1 \times A_2 \times B\}) \\
      = & \mu^X_{K_2}(A_1 \times A_2 \times B)
    \end{aligned}
  \end{equation}
  Especially, when \(A_1=A_2=E\), the equation is true as well.
  So only need to prove: \(\mu^X_{K_1}(E \times E \times B) = \mu^X_J(B)\).
  And
  \begin{equation}
    \begin{aligned}
        & \mu^X_{K_1}(E \times E \times B)                                                                          \\
      = & \mathbb{P}(\{X_{s_1} \in E, X_{s_2} \in E, (X_{t_1},\cdots,X_{t_n}) \in B \})                             \\
      = & \mathbb{P}(\{X_{s_1} \in E\})\mathbb{P}(\{X_{s_2} \in E\})\mathbb{P}(\{(X_{t_1},\cdots,X_{t_n}) \in B \}) \\
      = & \mathbb{P}(\{(X_{t_1},\cdots,X_{t_n}) \in B\})                                                            \\
      = & \mu^X_J(B)
    \end{aligned}
  \end{equation}
\end{solution}

\begin{problem}\label{pro:4}
  Assume \((\tau_k:k \in \mathbb{N}^+)\) is an i.i.d sequence of r.v. with exponential distribution with parameter \(\alpha>0\).
  Let \(S_n:=\sum_{k=1}^{n}\tau_k\). For \(t \geq 0,t \in \mathbb{R}\), let:
  \[
    N_t:=\sum_{n=1}^{\infty}\mathbbm{1}_{\{S_n \leq t\}},
    X_t:=\sum_{n=1}^{\infty}\mathbbm{1}_{\{S_n < t\}}
  \]
  Prove that \(N\) and \(X\) are modifications of each other, but they are not indistinguishable.
\end{problem}
\begin{solution}
  Since \(S_n = \sum_{k = 1}^n \tau_k\), where \((\tau_k: k \in \mathbb{N}^+)\) is i.i.d.,
  then by SLLN \(\frac{S_n}{n} \to \mathbb{E}(\tau_1) < \infty\).
  So \(S_n \to \infty\), then \(N_t, X_t\) are all well-defined r.v..
  Since \(\forall t \geq 0, t \in \mathbb{R}\), \(\mathbb{P}(\{N_t \neq X_t\}) = \mathbb{P}(\{S_n = t, \exists n \in \mathbb{N}^+\})\).
  Since \((\tau_k, k \in \mathbb{N}^+)\) are all continuous i.i.d. r.v. , then
  \((S_n, n \in \mathbb{N}^+)\) are all continuous r.v..
  Therefore, \(\mathbb{P}(\{S_n=t, \exists n \in \mathbb{N}^+\}) = \sum_{n = 1}^{\infty} \mathbb{P}(\{S_n = t\})=0\).
  So \(N\) and \(X\) are modifications.
  And \(\forall \omega \in \Omega\), \(t:= \tau_1(\omega)\), \(N_t = 1 \neq X_t = 0\),
  then \(\{N_t = X_t, \forall t \geq 0, t \in \mathbb{R}\} = \emptyset\).
  Thus, \(N\) and \(X\) are not indistinguishable.
\end{solution}

\begin{problem}\label{pro:5}
  Assume \(T\) is non-negetive r.v. with distribution function \(F\) continuous on \(\mathbb{R}\).
  Let \(X_t=\mathbbm{1}_{\{T \leq t\}}\).
  Prove that \(X\) is stochastically continuous.
\end{problem}
\begin{solution}
  \(\forall \varepsilon > 0, t \geq 0, t \in \mathbb{R}\), \(s \to t^+\), \(\mathbb{P}(|X_s-X_t| \geq \varepsilon)= \mathbb{P}(\{X_s-X_t \geq \varepsilon\})= \mathbb{P}(\{X_s = 1, X_t =0\}) = \mathbb{P}(\{t < T \leq s\})= F(s)-F(t) \to 0\).
  In the same way, we can get \(s \to t^-\), \(\mathbb{P}(|X_s-X_t| \geq \varepsilon) \to 0\).
  Therefore, \(X\) is stochastically continuous.
\end{solution}

\begin{problem}\label{pro:6}
  Assume \(I=\mathbb{Z}^+\), then the stochastic process \(X=(X_0,X_1,\cdots)\) is a r.v. from \(\Omega\) to \(E^\infty\).
  Define the distribution of \(X\), \(\mu_X\), as follows:
  \[
    \mu_X(A)=\mathbb{P}(X \in A),A \in \mathscr{E}^\infty
  \]
  Then stochastic process \(X,Y\) are equivalent \(\iff \mu_X=\mu_Y\).
\end{problem}
\begin{solution}
  \begin{enumerate}
    \item If \(X,Y\) are equivalent, so \(\forall J \in S(\mathbb{N}), \forall A \in E^{|J|},\mu_J^X(A) = \mathbb{P}(\{(X_{t_1},\cdots,X_{t_n}) \in A, (t_1,\cdots,t_n) = J\}) = \mathbb{P}(\{(Y_{t_1},\cdots,Y_{t_n}) \in A\})\).
      Since \(\mathscr{E}^{\infty} = \sigma(\mathscr{C})\), where \(\mathscr{C}:=\{A_J \times \prod_{i \in J^c}E_i: J \in S(\mathbb{N})\}\) is a semialgebraic set.
      Then \(\forall A_J \times \prod_{i \in J^c} E_i \in \mathscr{C}\),
      \begin{equation}
        \begin{aligned}
            & \mu_X(A)                                                             \\
          = & \mathbb{P}(X \in A_J \times \prod_{i \in J^c}E_i)                    \\
          = & \mathbb{P}((X_{t_1},\cdots,X_{t_n}) \in A_J, X_i \in E_i, i \in J^c) \\
          = & \mathbb{P}((X_{t_1},\cdots,X_{t_n}) \in A_J)                         \\
          = & \mu^X_J(A)                                                           \\
          = & \mu^Y_J(A)                                                           \\
          = & \mu_Y(A)
        \end{aligned}
      \end{equation}
      By the measure extension theorem, \(\mu_X(A) = \mu_Y(A), \forall A \in \mathscr{E}^{\infty}\).
    \item If \(\mu_X(A)=\mu_Y(A), \forall A \in \mathscr{E}^{\infty}\), then by the discussion above,
      we get easliy \(X, Y\) are equivalent.
  \end{enumerate}
\end{solution}
\end{document}
